{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './'\n",
    "train = pd.read_csv(data_path+'train.csv')\n",
    "feat = np.load('feat.npy', allow_pickle= True)\n",
    "path = np.load('path.npy')\n",
    "test = pd.read_csv(data_path +'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_np = pd.DataFrame()\n",
    "df_np['feat'] = feat\n",
    "df_np['path'] = path\n",
    "df_np\n",
    "df_train = pd.merge(df_np, train, on = 'path')\n",
    "df_test = pd.merge(df_np, test, on = 'path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing real testset and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct_test():\n",
    "\n",
    "    lmfcc = []\n",
    "    lmfcc_mean = []\n",
    "    lmfcc_std = []\n",
    "    lstft = []\n",
    "    lchroma = []\n",
    "    path_names = []\n",
    "    lmel = []\n",
    "    lcontrast = []\n",
    "    ltonnetz = []\n",
    "    \n",
    "    \n",
    "    for wav in os.listdir(data_path + '/class_samples/'):\n",
    "              \n",
    "        if wav in test['path'].values:\n",
    "            sound, sr = librosa.load(data_path + '/class_samples/' + wav, mono=True, sr=None)\n",
    "            sound_str = librosa.effects.time_stretch(sound, 0.5)\n",
    "            stft = np.abs(librosa.stft(sound_str))\n",
    "            chroma = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
    "            mel = np.mean(librosa.feature.melspectrogram(sound_str, sr=16000).T,axis=0)\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=16000).T,axis=0)\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound_str), sr=16000).T,axis=0)\n",
    "            mfcc = librosa.feature.mfcc(sound_str, sr=16000, n_mfcc=13)\n",
    "            mfcc_mean = np.mean(mfcc)\n",
    "            mfcc_std = np.std(mfcc)\n",
    "            \n",
    "            path_names.append(wav)\n",
    "            lstft.append(np.mean(stft))\n",
    "            lchroma.append(np.mean(chroma))\n",
    "            lmfcc.append(mfcc)\n",
    "            lmfcc_mean.append(mfcc_mean)\n",
    "            lmfcc_std.append(mfcc_std)\n",
    "            lcontrast.append(np.mean(contrast))\n",
    "            lmel.append(np.mean(mel))\n",
    "            ltonnetz.append(np.mean(tonnetz))\n",
    "            \n",
    "         \n",
    "          \n",
    "    return (path_names, lmfcc, lmfcc_mean, lmfcc_std, lstft, lchroma, lcontrast, lmel, ltonnetz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[0.001427957970076773, 0.009446872888140539, 0.001214988255603058, 0.017388306797007216, 0.0011864425270624987, 0.007165589102509226, -0.007028336054776519, 0.0036018177505590123, -0.012124548700990181, 0.010857408660042452, -0.010888695792875991, 0.00611783593137688, -0.014318993200171626, -0.016278647668317946, -0.004488496092601921, -0.0066781726981452435, 0.020522662458118773, -0.00693800222875568, 0.012591859202314206, -0.015721342868708858]\n"
     ]
    }
   ],
   "source": [
    "b = funct_test()\n",
    "print(len(b))\n",
    "print(b[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.DataFrame()\n",
    "df_test['path']=b[0]\n",
    "df_test['mfccs']=b[1]\n",
    "df_test['std']=b[3]\n",
    "df_test['mean']=b[2]\n",
    "df_test['stft']=b[4]\n",
    "df_test['chroma']=b[5]\n",
    "df_test['contrast']=b[6]\n",
    "df_test['mel']=b[7]\n",
    "df_test['tonnetz']=b[8]\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('./real_testset.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_testset = pd.read_csv('real_testset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_realtest = real_testset.iloc[:,[2,3,4,5,6,7,8]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.84537469e+01 -2.65369148e+01  3.39531809e-01  5.59725271e-01\n",
      "   2.32662099e+01  4.09553240e-01  1.42795797e-03]\n",
      " [ 1.14542354e+02 -3.11992400e+01  2.31030926e-01  4.31857581e-01\n",
      "   2.13907789e+01  1.63502928e+00  9.44687289e-03]\n",
      " [ 1.13671649e+02 -2.22211450e+01  1.30528942e-01  6.87913217e-01\n",
      "   1.85424354e+01  7.72524881e-02  1.21498826e-03]\n",
      " [ 1.04006474e+02 -1.86801195e+01  1.74299106e-01  7.19819399e-01\n",
      "   1.97138816e+01  1.90450957e-01  1.73883068e-02]\n",
      " [ 1.19335912e+02 -2.47439056e+01  4.29659903e-01  5.96932950e-01\n",
      "   2.18139294e+01  9.75148900e-01  1.18644253e-03]\n",
      " [ 1.19436174e+02 -2.51633987e+01  2.94347376e-01  6.26856018e-01\n",
      "   1.98660701e+01  7.93304275e-01  7.16558910e-03]\n",
      " [ 1.06464199e+02 -2.72209522e+01  4.05274510e-01  5.18832131e-01\n",
      "   1.96147207e+01  1.28028228e+00 -7.02833605e-03]\n",
      " [ 1.26759537e+02 -3.10089230e+01  2.08659172e-01  6.22409695e-01\n",
      "   1.97153888e+01  7.73492690e-01  3.60181775e-03]\n",
      " [ 1.19135785e+02 -2.76837842e+01  2.11839646e-01  6.24612953e-01\n",
      "   1.96686976e+01  1.08106932e+00 -1.21245487e-02]\n",
      " [ 1.22569337e+02 -2.74715096e+01  4.08515722e-01  6.12088093e-01\n",
      "   2.09707246e+01  1.42853208e+00  1.08574087e-02]\n",
      " [ 1.10036845e+02 -3.21974138e+01  1.64548814e-01  5.36146512e-01\n",
      "   1.99697964e+01  6.57754009e-01 -1.08886958e-02]\n",
      " [ 1.07942120e+02 -2.07659122e+01  3.81887108e-01  5.90269891e-01\n",
      "   2.18876775e+01  2.86220667e+00  6.11783593e-03]\n",
      " [ 1.51887115e+02 -4.12327468e+01  1.03454478e-01  7.26946559e-01\n",
      "   1.96804359e+01  1.68442788e-01 -1.43189932e-02]\n",
      " [ 1.44887824e+02 -3.16388137e+01  8.58626813e-02  5.18004999e-01\n",
      "   2.10990159e+01  2.64944633e-01 -1.62786477e-02]\n",
      " [ 1.50564840e+02 -3.68022895e+01  2.82137811e-01  6.62363355e-01\n",
      "   1.92006018e+01  7.99166415e-01 -4.48849609e-03]\n",
      " [ 1.53575772e+02 -3.37099550e+01  5.05377315e-02  6.31363355e-01\n",
      "   2.06018562e+01  3.70131010e-02 -6.67817270e-03]\n",
      " [ 1.36770376e+02 -3.28824021e+01  1.20186396e-01  6.33761182e-01\n",
      "   1.88514208e+01  3.81817821e-01  2.05226625e-02]\n",
      " [ 7.49257232e+01 -2.53222074e+01  2.35129684e-01  7.33077202e-01\n",
      "   2.15767004e+01  1.89518176e-01 -6.93800223e-03]\n",
      " [ 1.50465605e+02 -3.05747761e+01  1.64977193e-01  6.57034004e-01\n",
      "   1.94965544e+01  7.91246158e-01  1.25918592e-02]\n",
      " [ 1.12349229e+02 -2.77054931e+01  9.91542637e-02  6.98246443e-01\n",
      "   1.82856290e+01  5.67913085e-02 -1.57213429e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(X_realtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing train dataset and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funct_np():\n",
    "   \n",
    "    lmfcc = []\n",
    "    lmfcc_mean = []\n",
    "    lmfcc_std = []\n",
    "    lstft = []\n",
    "    lchroma = []\n",
    "    path_names = []\n",
    "    path_words = []\n",
    "    lmel = []\n",
    "    lcontrast = []\n",
    "    ltonnetz = []\n",
    "    \n",
    "    for wav in os.listdir(data_path + '/class_samples/'):\n",
    "  \n",
    "        if wav in train['path'].values:\n",
    "            sound, sr = librosa.load(data_path + '/class_samples/' + wav, mono=True, sr=None)\n",
    "            sound_str = librosa.effects.time_stretch(sound, 0.5)\n",
    "            stft = np.abs(librosa.stft(sound_str))\n",
    "            chroma = librosa.feature.chroma_stft(S=stft, sr=sr)\n",
    "            mel = np.mean(librosa.feature.melspectrogram(sound_str, sr=16000).T,axis=0)\n",
    "            contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=16000).T,axis=0)\n",
    "            tonnetz = np.mean(librosa.feature.tonnetz(y=librosa.effects.harmonic(sound_str), sr=16000).T,axis=0)\n",
    "            mfcc = librosa.feature.mfcc(sound_str, sr=16000, n_mfcc=13)\n",
    "            mfcc_mean = np.mean(mfcc)\n",
    "            mfcc_std = np.std(mfcc)\n",
    "                       \n",
    "            get_val = train['path'].isin([wav])\n",
    "            idx = list(get_val[get_val==True].index) \n",
    "            label = train['word'][idx[0]]\n",
    "           \n",
    "            path_words.append(label)  \n",
    "            path_names.append(wav)\n",
    "            lstft.append(np.mean(stft))\n",
    "            lchroma.append(np.mean(chroma))\n",
    "            lmfcc.append(mfcc)\n",
    "            lmfcc_mean.append(mfcc_mean)\n",
    "            lmfcc_std.append(mfcc_std)\n",
    "            lcontrast.append(np.mean(contrast))\n",
    "            lmel.append(np.mean(mel))\n",
    "            ltonnetz.append(np.mean(tonnetz))\n",
    "\n",
    "       \n",
    "    return (path_names, lmfcc, lmfcc_mean, lmfcc_std, lstft, lchroma, lmel, lcontrast, ltonnetz, path_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\librosa\\core\\pitch.py:145: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  warnings.warn('Trying to estimate tuning from empty frequency set.')\n"
     ]
    }
   ],
   "source": [
    "a = funct_np()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "224\n"
     ]
    }
   ],
   "source": [
    "print(len(a[9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.DataFrame()\n",
    "dataframe['path']=a[0]\n",
    "dataframe['mfccs']=a[1]\n",
    "dataframe['std']=a[3]\n",
    "dataframe['mean']=a[2]\n",
    "dataframe['stft']=a[4]\n",
    "dataframe['chroma']=a[5]\n",
    "dataframe['contrast']=a[6]\n",
    "dataframe['mel']=a[7]\n",
    "dataframe['tonnetz']=a[8]\n",
    "dataframe['word']=a[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('./sumdataframe.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('sumdataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,[2,3,4,5,6,7,8]].values\n",
    "y = dataset.iloc[:, 9].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n",
      "224\n"
     ]
    }
   ],
   "source": [
    "print(len(np.unique(y)))\n",
    "print(len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode class values as integers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "#sample_pred = dummy_y.argmax(1) #reversing to an integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, dummy_y, test_size = 0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train) #we fit and transform for the train set, the test set is only transformed\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179, 7) 1253\n",
      "(45, 35)\n",
      "(45, 7) 315\n",
      "(179, 35)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_train.size)\n",
    "print(y_test.shape)\n",
    "print(X_test.shape, X_test.size)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize ann\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=7, units=21, kernel_initializer=\"uniform\")`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#Input layer and hidden layer -- here tuning was applied\n",
    "classifier.add(Dense(output_dim=21, init='uniform', activation='relu', input_dim=7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=21, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=21, init='uniform', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=35, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "classifier.add(Dense(output_dim=35, init='uniform', activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "179/179 [==============================] - ETA: 6s - loss: 3.5555 - acc: 0.0000e+0 - 0s 3ms/step - loss: 3.5545 - acc: 0.0391\n",
      "Epoch 2/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.5521 - acc: 0.100 - 0s 295us/step - loss: 3.5484 - acc: 0.0615\n",
      "Epoch 3/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.5403 - acc: 0.100 - 0s 273us/step - loss: 3.5395 - acc: 0.0615\n",
      "Epoch 4/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.5537 - acc: 0.0000e+0 - 0s 301us/step - loss: 3.5219 - acc: 0.0615\n",
      "Epoch 5/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.4194 - acc: 0.100 - ETA: 0s - loss: 3.4941 - acc: 0.058 - 0s 440us/step - loss: 3.4897 - acc: 0.0615\n",
      "Epoch 6/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.4984 - acc: 0.0000e+0 - 0s 273us/step - loss: 3.4468 - acc: 0.0615\n",
      "Epoch 7/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.4013 - acc: 0.0000e+0 - 0s 290us/step - loss: 3.3961 - acc: 0.0615\n",
      "Epoch 8/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1337 - acc: 0.200 - 0s 318us/step - loss: 3.3598 - acc: 0.0615\n",
      "Epoch 9/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3397 - acc: 0.100 - 0s 312us/step - loss: 3.3308 - acc: 0.0670\n",
      "Epoch 10/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.2950 - acc: 0.0000e+0 - 0s 306us/step - loss: 3.3059 - acc: 0.0950\n",
      "Epoch 11/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1272 - acc: 0.100 - ETA: 0s - loss: 3.3395 - acc: 0.070 - 0s 518us/step - loss: 3.2876 - acc: 0.0894\n",
      "Epoch 12/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.4421 - acc: 0.0000e+0 - 0s 295us/step - loss: 3.2687 - acc: 0.0950\n",
      "Epoch 13/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3116 - acc: 0.100 - 0s 284us/step - loss: 3.2560 - acc: 0.1006\n",
      "Epoch 14/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1722 - acc: 0.0000e+0 - 0s 267us/step - loss: 3.2423 - acc: 0.0950\n",
      "Epoch 15/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0551 - acc: 0.200 - 0s 295us/step - loss: 3.2349 - acc: 0.0950\n",
      "Epoch 16/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3021 - acc: 0.100 - 0s 295us/step - loss: 3.2237 - acc: 0.0950\n",
      "Epoch 17/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0670 - acc: 0.100 - 0s 256us/step - loss: 3.2182 - acc: 0.0950\n",
      "Epoch 18/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3534 - acc: 0.0000e+0 - ETA: 0s - loss: 3.2017 - acc: 0.0867    - 0s 474us/step - loss: 3.2119 - acc: 0.0950\n",
      "Epoch 19/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9549 - acc: 0.200 - 0s 256us/step - loss: 3.2038 - acc: 0.0950\n",
      "Epoch 20/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3327 - acc: 0.0000e+0 - 0s 279us/step - loss: 3.1995 - acc: 0.0950\n",
      "Epoch 21/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1604 - acc: 0.0000e+0 - 0s 256us/step - loss: 3.1907 - acc: 0.0950\n",
      "Epoch 22/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0269 - acc: 0.200 - 0s 223us/step - loss: 3.1882 - acc: 0.0950\n",
      "Epoch 23/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.4950 - acc: 0.0000e+0 - 0s 228us/step - loss: 3.1825 - acc: 0.0950\n",
      "Epoch 24/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9916 - acc: 0.200 - 0s 295us/step - loss: 3.1798 - acc: 0.0950\n",
      "Epoch 25/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3800 - acc: 0.100 - 0s 284us/step - loss: 3.1749 - acc: 0.0950\n",
      "Epoch 26/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1540 - acc: 0.100 - 0s 256us/step - loss: 3.1705 - acc: 0.0950\n",
      "Epoch 27/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0528 - acc: 0.100 - 0s 284us/step - loss: 3.1655 - acc: 0.0950\n",
      "Epoch 28/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1969 - acc: 0.0000e+0 - 0s 240us/step - loss: 3.1633 - acc: 0.0950\n",
      "Epoch 29/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1224 - acc: 0.100 - 0s 267us/step - loss: 3.1606 - acc: 0.0950\n",
      "Epoch 30/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0510 - acc: 0.100 - 0s 240us/step - loss: 3.1565 - acc: 0.0950\n",
      "Epoch 31/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3395 - acc: 0.0000e+0 - 0s 251us/step - loss: 3.1505 - acc: 0.0950\n",
      "Epoch 32/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1600 - acc: 0.200 - 0s 262us/step - loss: 3.1465 - acc: 0.0950\n",
      "Epoch 33/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.4135 - acc: 0.0000e+0 - 0s 295us/step - loss: 3.1423 - acc: 0.0950\n",
      "Epoch 34/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.2082 - acc: 0.0000e+0 - 0s 284us/step - loss: 3.1406 - acc: 0.0950\n",
      "Epoch 35/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0612 - acc: 0.100 - 0s 312us/step - loss: 3.1348 - acc: 0.0950\n",
      "Epoch 36/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8114 - acc: 0.300 - 0s 295us/step - loss: 3.1302 - acc: 0.0950\n",
      "Epoch 37/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9058 - acc: 0.0000e+0 - 0s 290us/step - loss: 3.1286 - acc: 0.1006\n",
      "Epoch 38/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9723 - acc: 0.0000e+0 - 0s 295us/step - loss: 3.1233 - acc: 0.0950\n",
      "Epoch 39/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9789 - acc: 0.0000e+0 - 0s 290us/step - loss: 3.1196 - acc: 0.0950\n",
      "Epoch 40/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7760 - acc: 0.100 - ETA: 0s - loss: 3.1293 - acc: 0.094 - 0s 412us/step - loss: 3.1144 - acc: 0.0950\n",
      "Epoch 41/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0763 - acc: 0.100 - 0s 279us/step - loss: 3.1085 - acc: 0.1006\n",
      "Epoch 42/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.5667 - acc: 0.0000e+0 - 0s 306us/step - loss: 3.1060 - acc: 0.0950\n",
      "Epoch 43/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.3589 - acc: 0.0000e+0 - ETA: 0s - loss: 3.0948 - acc: 0.0941    - 0s 379us/step - loss: 3.1008 - acc: 0.0950\n",
      "Epoch 44/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.2494 - acc: 0.0000e+0 - ETA: 0s - loss: 3.0956 - acc: 0.1000    - 0s 407us/step - loss: 3.0954 - acc: 0.1006\n",
      "Epoch 45/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8712 - acc: 0.300 - 0s 318us/step - loss: 3.0933 - acc: 0.1061\n",
      "Epoch 46/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9377 - acc: 0.0000e+0 - 0s 295us/step - loss: 3.0863 - acc: 0.1006\n",
      "Epoch 47/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7088 - acc: 0.200 - 0s 240us/step - loss: 3.0832 - acc: 0.1006\n",
      "Epoch 48/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7778 - acc: 0.100 - 0s 223us/step - loss: 3.0797 - acc: 0.1006\n",
      "Epoch 49/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9933 - acc: 0.200 - 0s 262us/step - loss: 3.0707 - acc: 0.1006\n",
      "Epoch 50/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9850 - acc: 0.100 - 0s 251us/step - loss: 3.0665 - acc: 0.1061\n",
      "Epoch 51/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0745 - acc: 0.0000e+0 - 0s 284us/step - loss: 3.0628 - acc: 0.1061\n",
      "Epoch 52/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7749 - acc: 0.200 - 0s 262us/step - loss: 3.0582 - acc: 0.1173\n",
      "Epoch 53/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1785 - acc: 0.100 - ETA: 0s - loss: 3.0354 - acc: 0.113 - 0s 429us/step - loss: 3.0520 - acc: 0.1117\n",
      "Epoch 54/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0793 - acc: 0.100 - ETA: 0s - loss: 3.0394 - acc: 0.107 - 0s 468us/step - loss: 3.0438 - acc: 0.1173\n",
      "Epoch 55/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9174 - acc: 0.300 - ETA: 0s - loss: 3.0253 - acc: 0.118 - 0s 396us/step - loss: 3.0408 - acc: 0.1117\n",
      "Epoch 56/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.2181 - acc: 0.0000e+0 - 0s 284us/step - loss: 3.0333 - acc: 0.1173\n",
      "Epoch 57/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.2163 - acc: 0.100 - 0s 273us/step - loss: 3.0288 - acc: 0.1229\n",
      "Epoch 58/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1644 - acc: 0.0000e+0 - 0s 273us/step - loss: 3.0223 - acc: 0.1173\n",
      "Epoch 59/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0217 - acc: 0.0000e+0 - 0s 256us/step - loss: 3.0160 - acc: 0.1173\n",
      "Epoch 60/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9141 - acc: 0.200 - 0s 295us/step - loss: 3.0099 - acc: 0.1285\n",
      "Epoch 61/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0465 - acc: 0.100 - 0s 301us/step - loss: 3.0014 - acc: 0.1285\n",
      "Epoch 62/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9995 - acc: 0.0000e+0 - 0s 256us/step - loss: 2.9982 - acc: 0.1229\n",
      "Epoch 63/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0780 - acc: 0.100 - 0s 323us/step - loss: 2.9924 - acc: 0.1341\n",
      "Epoch 64/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.5394 - acc: 0.300 - 0s 245us/step - loss: 2.9826 - acc: 0.1229\n",
      "Epoch 65/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1426 - acc: 0.100 - 0s 267us/step - loss: 2.9786 - acc: 0.1285\n",
      "Epoch 66/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0403 - acc: 0.0000e+0 - 0s 251us/step - loss: 2.9738 - acc: 0.1397\n",
      "Epoch 67/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0230 - acc: 0.100 - 0s 267us/step - loss: 2.9610 - acc: 0.1453\n",
      "Epoch 68/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.5906 - acc: 0.200 - 0s 256us/step - loss: 2.9547 - acc: 0.1453\n",
      "Epoch 69/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8825 - acc: 0.100 - ETA: 0s - loss: 2.9458 - acc: 0.153 - 0s 462us/step - loss: 2.9489 - acc: 0.1508\n",
      "Epoch 70/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0033 - acc: 0.0000e+0 - 0s 373us/step - loss: 2.9406 - acc: 0.1453\n",
      "Epoch 71/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9190 - acc: 0.100 - 0s 323us/step - loss: 2.9340 - acc: 0.1453\n",
      "Epoch 72/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8499 - acc: 0.300 - 0s 273us/step - loss: 2.9244 - acc: 0.1453\n",
      "Epoch 73/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.6703 - acc: 0.300 - 0s 267us/step - loss: 2.9171 - acc: 0.1453\n",
      "Epoch 74/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7565 - acc: 0.100 - 0s 279us/step - loss: 2.9077 - acc: 0.1453\n",
      "Epoch 75/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8132 - acc: 0.100 - 0s 267us/step - loss: 2.8994 - acc: 0.1508\n",
      "Epoch 76/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.1391 - acc: 0.100 - 0s 245us/step - loss: 2.8899 - acc: 0.1564\n",
      "Epoch 77/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7255 - acc: 0.200 - 0s 267us/step - loss: 2.8845 - acc: 0.1564\n",
      "Epoch 78/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0358 - acc: 0.100 - 0s 279us/step - loss: 2.8751 - acc: 0.1508\n",
      "Epoch 79/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8422 - acc: 0.300 - 0s 279us/step - loss: 2.8657 - acc: 0.1508\n",
      "Epoch 80/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8976 - acc: 0.200 - 0s 284us/step - loss: 2.8563 - acc: 0.1508\n",
      "Epoch 81/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7983 - acc: 0.100 - 0s 262us/step - loss: 2.8450 - acc: 0.1564\n",
      "Epoch 82/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7202 - acc: 0.300 - 0s 256us/step - loss: 2.8376 - acc: 0.1620\n",
      "Epoch 83/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7083 - acc: 0.100 - 0s 279us/step - loss: 2.8298 - acc: 0.1620\n",
      "Epoch 84/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.6752 - acc: 0.100 - 0s 245us/step - loss: 2.8205 - acc: 0.1620\n",
      "Epoch 85/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.6642 - acc: 0.200 - 0s 262us/step - loss: 2.8145 - acc: 0.1620\n",
      "Epoch 86/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.4300 - acc: 0.200 - 0s 290us/step - loss: 2.8032 - acc: 0.1676\n",
      "Epoch 87/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.6170 - acc: 0.200 - 0s 262us/step - loss: 2.7932 - acc: 0.1788\n",
      "Epoch 88/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.6345 - acc: 0.300 - 0s 262us/step - loss: 2.7835 - acc: 0.1732\n",
      "Epoch 89/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7207 - acc: 0.200 - 0s 267us/step - loss: 2.7773 - acc: 0.1508\n",
      "Epoch 90/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9214 - acc: 0.0000e+0 - 0s 290us/step - loss: 2.7642 - acc: 0.1732\n",
      "Epoch 91/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.8593 - acc: 0.200 - 0s 251us/step - loss: 2.7578 - acc: 0.1676\n",
      "Epoch 92/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9534 - acc: 0.100 - ETA: 0s - loss: 2.7568 - acc: 0.162 - 0s 440us/step - loss: 2.7491 - acc: 0.1620\n",
      "Epoch 93/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.4800 - acc: 0.100 - ETA: 0s - loss: 2.7174 - acc: 0.168 - 0s 446us/step - loss: 2.7360 - acc: 0.1564\n",
      "Epoch 94/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 3.0891 - acc: 0.0000e+0 - 0s 279us/step - loss: 2.7281 - acc: 0.1732\n",
      "Epoch 95/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.9305 - acc: 0.0000e+0 - 0s 334us/step - loss: 2.7190 - acc: 0.1676\n",
      "Epoch 96/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7624 - acc: 0.100 - 0s 267us/step - loss: 2.7140 - acc: 0.1676\n",
      "Epoch 97/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.3222 - acc: 0.300 - 0s 262us/step - loss: 2.7054 - acc: 0.1732\n",
      "Epoch 98/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.5947 - acc: 0.200 - 0s 262us/step - loss: 2.6913 - acc: 0.1788\n",
      "Epoch 99/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.3986 - acc: 0.200 - 0s 273us/step - loss: 2.6846 - acc: 0.1788\n",
      "Epoch 100/100\n",
      "179/179 [==============================] - ETA: 0s - loss: 2.7592 - acc: 0.200 - 0s 306us/step - loss: 2.6762 - acc: 0.1844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15d7fb62ef0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size = 10, nb_epoch =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['three' 'eight' 'three' 'marvin' 'three' 'three' 'happy' 'two' 'three'\n",
      " 'stop' 'four' 'dog' 'four' 'nine' 'three' 'down' 'marvin' 'nine' 'off'\n",
      " 'three' 'one' 'one' 'eight' 'happy' 'three' 'dog' 'three' 'three' 'three'\n",
      " 'off' 'off' 'three' 'dog' 'three' 'three' 'three' 'four' 'marvin' 'down'\n",
      " 'eight' 'four' 'down' 'no' 'go' 'on']\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "predictions = y_pred.argmax(1)\n",
    "\n",
    "print(encoder.inverse_transform(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cigdem\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eight' 'eight' 'eight' 'eight' 'eight' 'eight' 'eight' 'eight' 'eight'\n",
      " 'eight' 'eight' 'eight' 'eight' 'eight' 'eight' 'eight' 'eight' 'eight'\n",
      " 'eight' 'eight']\n"
     ]
    }
   ],
   "source": [
    "y_predreal = classifier.predict(X_realtest)\n",
    "predictions_real = y_predreal.argmax(1)\n",
    "words = encoder.inverse_transform(predictions_real)\n",
    "print(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = real_testset\n",
    "result = result.drop(['mfccs', 'std', 'mean', 'stft', 'chroma', 'contrast', 'mel', 'tonnetz', ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['word'] = words\n",
    "result.to_csv(\"result.csv\", sep=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
